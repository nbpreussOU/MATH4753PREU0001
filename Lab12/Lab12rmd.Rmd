---
title: "Lab 12"
author: "Nathan Preuss"
date:  "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    csl: biomed-central.csl
    df_print: paged
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    number_sections: yes
    theme: journal
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Task 1

Working Directory

```{r}
getwd()
```

# Task 2

## Making One Sample t-test

```{r}
# one sample t-test
set.seed(55);x1=rnorm(30,mean=25,sd=5)
t.test(x1, mu = 22)
t.test(x1, mu = 23)
t.test(x1, mu = 24)
t.test(x1, mu = 25)
t.test(x1, mu = 26)

```

We can reject the null hypothesis that $\mu_0 = 22$ because the t value was 3.3863 and the p-value was .0020.  The confidence interval for this test and the following tests for the mean is $(23.3019, 27.2732)$.

We can reject the null hypothesis that $\mu_0 = 23$ because the t value was 2.3563 and the p-value was .0254.

We cannot reject the null hypothesis that $\mu_0 = 24$ because the t value was 1.3263 and the p-value was .1951.

We cannot reject the null hypothesis that $\mu_0 = 25$ because the t value was 0.2962 and the p-value was .7692.

We cannot reject the null hypothesis that $\mu_0 = 26$ because the t value was -0.7338 and the p-value was .469


## Making the boxplot

```{r}
boxplot(x1, main="Sample x1")

t.test(x1,mu=28)
ci=t.test(x1,mu=23)$conf.int
ci
abline(h=c(ci,mean(x1)),col=c("Red","Red","Green"))
```

## Creating t-calc

I will be using the formula provided in the lab assignment but solving it in R.

```{r}
tcalc = (mean(x1) - 24) / (sd(x1)/sqrt(length(x1)))
tcalc
```

$t_{calc} = 1.3262$, with $H_0: \mu_0 = 24$.

## Using mypvalue

```{r}
#### FUNCTION for Pvalues 
# Display P-value areas
mypvalue=function(t0,xmax=4,n=20, alpha=0.05){
#calculate alpha/2
va=round(pt(-t0,df=n-1),4)
pv=2*va

# plot the t dist
curve(dt(x,df=n-1),xlim=c(-xmax,xmax),ylab="T Density",xlab=expression(t),
main=substitute(paste("P-value=", pv, " alpha=", alpha)))


# set up points on the polygon to the right
xcurve=seq(t0,xmax,length=1000)
ycurve=dt(xcurve,df=n-1)

# set up points to the left
xlcurve=seq(-t0,-xmax,length=1000)
ylcurve=dt(xcurve,df=n-1)

# Shade in the polygon defined by the line segments
polygon(c(t0,xcurve,xmax),c(0,ycurve,0),col="green")
polygon(c(-t0,xlcurve,-xmax),c(0,ylcurve,0),col="green")

# make quantiles
q=qt(1-alpha/2,n-1)
abline( v=c(q,-q),lwd=2) # plot the cut off t value 
axis(3,c(q,-q),c(expression(abs(t[alpha/2])),expression(-abs(t[alpha/2]))))


# Annotation
text(0.5*(t0+xmax),max(ycurve),substitute(paste(area, "=",va)))
text(-0.5*(t0+xmax),max(ycurve),expression(area))

return(list(q=q,pvalue=pv))
}
##### END of FUNCTION for P VALUES    #####

mypvalue(tcalc)
#t.test(x1,mu=23)
```

The rejection region is $t \lt -2.0930, t \gt 2.0930$.

The p-value is .2004.

The t-calc does not lie in the rejection region.

## Using bootstrapping

```{r}
### bootstrap pvalues
bootpval<-function(x,conf.level=0.95,iter=3000,mu0=0, test="two"){
n=length(x)
y=x-mean(x)+mu0  # transform the data so that it is centered at the NULL
rs.mat<-c()    #rs.mat will become a resample matrix -- now it is an empty vector
xrs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
rs.mat<-cbind(rs.mat,sample(y,n,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
xrs.mat<-cbind(xrs.mat,sample(x,n,replace=TRUE)) #sampling from x cbind -- column bind -- binds the vectors together by columns

}

tstat<-function(z){ # The value of t when the NULL is assumed true (xbar-muo)/z/sqrt(n)
sqrt(n)*(mean(z)-mu0)/sd(z)
}

tcalc=tstat(x) # t for the data collected
ytstat=apply(rs.mat,2,tstat) # tstat of resampled y's, ytstat is a vector and will have iter values in it
xstat=apply(xrs.mat,2,mean)  # mean of resampled x's
alpha=1-conf.level # calculating alpha
ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(ytstat[ytstat>abs(tcalc) | ytstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(ytstat[ytstat>tcalc])/iter,
length(ytstat[ytstat<xstat])/iter))

h=hist(ytstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
if(test=="upper"){
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Gray",length(mid)-ncolr),rep("Green",ncolr))
}

if(test=="lower"){
ncoll=length(mid[mid<=  -abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll))
}
hist(ytstat,col=col,freq=FALSE,las=1,main="",xlab=expression(T[stat]))
#segments(ci[1],0,ci[2],0,lwd=2)
pround=round(pvalue,4)
title(substitute(paste(P[value],"=",pround)))
return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}

bootpval(x=x1,mu0=22,test="two")
bootpval(x=x1,mu0=23,test="two")
bootpval(x=x1,mu0=24,test="two")
bootpval(x=x1,mu0=25,test="two")
bootpval(x=x1,mu0=26,test="two")
######### End Bootstrap pvalues
```

For the null hypothesis that $\mu_0 = 22$, the old t value was 3.3863,  the old p-value was .0020, and the old confidence interval was $(23.3019, 27.2732)$. For the new test, the t value was 3.3863, the p-value was .0026, and the confidence interval was $(23.4318, 27.1286)$.

For the null hypothesis that $\mu_0 = 23$, the old t value was 2.3563,  the old p-value was .0254, and the old confidence interval was $(23.3019, 27.2732)$. For the new test, the t value was 2.356, the p-value was .02233, and the confidence interval was $(23.3732, 27.1867)$.

For the null hypothesis that $\mu_0 = 24$, the old t value was 1.3263,  the old p-value was .1951, and the old confidence interval was $(23.3019, 27.2732)$. For the new test, the t value was 1.3262, the p-value was .19, and the confidence interval was $(23.4406, 27.1271)$.

For the null hypothesis that $\mu_0 = 25$, the old t value was .2962,  the old p-value was .7692 and the old confidence interval was $(23.3019, 27.2732)$. For the new test, the t value was .2962, the p-value was .7697, and the confidence interval was $(23.4237, 27.1889)$.

For the null hypothesis that $\mu_0 = 26$, the old t value was -0.7338,  the old p-value was .469, and the old confidence interval was $(23.3019, 27.2732)$. For the new test, the t value was -0.7337, the p-value was .457, and the confidence interval was $(23.4185, 27.1310)$.

In general, the bootstrap values and the t-test values are practically identical for all values, differing at most by a few hundreths.

# Task 3

## Var test

```{r}
set.seed(30);x=rnorm(15,mean=10,sd=7)
set.seed(40);y=rnorm(20,mean=12,sd=4)
var.test(x, y)
```

As a result of the var.test, the variances for x and y are not equal because the confidence interval (1.2604, 9.544) does not contain 1.  Therefore, I will be setting var.equal to FALSE in the upcoming code.

```{r}
t.test(y, x, mu = 0, var.equal = FALSE, conf.level=.95)
t.test(y, x, mu = 2, var.equal = FALSE, conf.level=.95)
```

In this case, the p-value for $H_0: \mu_y - mu_x = 0$ is .0876, so the null hypothesis is accepted, such that it is probable that the difference in means of y and x is 0.
Furthermore, the p-value for $H_0: \mu_y - mu_x = 2$ is .4216, so the null hypothesis is accepted, and it is probable that the difference in means between x and y is 2.
Curiously, even samples that should pass the t-tests occasionally fail them.  In the case of the first test, the difference in the means is 2 because we set it that way, and yet it failed the test.

# Test 4

## Var test

```{r}
set.seed(30);x=rnorm(15,mean=10,sd=4)   
set.seed(40);y=rnorm(20,mean=12,sd=4)
var.test(x,y)
```

In this case, x and y are likely to have the same variance because the confidence interval (.4116, 3.1164) contains 1. Therefore, I will be setting var.equal to TRUE.

```{r}
t.test(y, x, mu = 0, var.equal = TRUE, conf.level=.95)
t.test(y, x, mu = 2, var.equal = TRUE, conf.level=.95)
```

In this case, the p-value for $H_0: \mu_y - mu_x = 0$ is .04712, so the null hypothesis is rejected.
In this case, the p-value for $H_0: \mu_y - mu_x = 2$ is .5519, so the null hypothesis is accepted.
I learned that changing the variance for samples with the same mean can influence whether the null hypothesis is accepted or rejected.

# Task 5

## Bootstrap values for task 3

```{r}
set.seed(30);x=rnorm(15,mean=10,sd=7)
set.seed(40);y=rnorm(20,mean=12,sd=4)

## Bootstrap interval for a two sample test
boot2pval<-function(x1,x2,conf.level=0.95,iter=3000,mudiff=0, test="two"){
n1=length(x1)
n2=length(x2)
y1=x1-mean(x1)+mean(c(x1,x2))  # transform the data so that it is centered at the NULL
y2=x2-mean(x2)+mean(c(x1,x2))
y1rs.mat<-c()    #rs.mat will be come a resample matrix -- now it is an empty vector
x1rs.mat<-c()
y2rs.mat<-c()
x2rs.mat<-c()
for(i in 1:iter){ # for loop - the loop will go around iter times
y1rs.mat<-cbind(y1rs.mat,sample(y1,n1,replace=TRUE)) #sampling from y cbind -- column bind -- binds the vectors together by columns
y2rs.mat<-cbind(y2rs.mat,sample(y2,n2,replace=TRUE))

}
x1rs.mat<-y1rs.mat+mean(x1)-mean(c(x1,x2))
x2rs.mat<-y2rs.mat+mean(x2)-mean(c(x1,x2))

xbar1=mean(x1)
xbar2=mean(x2)
sx1sq=var(x1)
sx2sq=var(x2)

tcalc=(xbar1-xbar2-mudiff)/sqrt(sx1sq/n1+sx2sq/n2)

sy1sq=apply(y1rs.mat,2,var)
sy2sq=apply(y2rs.mat,2,var) 
y1bar=apply(y1rs.mat,2,mean)
y2bar=apply(y2rs.mat,2,mean)

tstat=(y1bar-y2bar-mudiff)/sqrt(sy1sq/n1+sy2sq/n2)


alpha=1-conf.level # calculating alpha
#ci=quantile(xstat,c(alpha/2,1-alpha/2))# Nice way to form a confidence interval
pvalue=ifelse(test=="two",length(tstat[tstat>abs(tcalc) | tstat < -abs(tcalc)])/iter,
ifelse(test=="upper",length(tstat[tstat>tcalc])/iter,
length(ytstat[tstat<tcalc])/iter))

h=hist(tstat,plot=FALSE)
mid=h$mid
if(test=="two"){
ncoll=length(mid[mid<= -abs(tcalc)])
ncolr=length(mid[mid>=  abs(tcalc)])
col=c(rep("Green",ncoll),rep("Gray",length(mid)-ncoll-ncolr),rep("Green",ncolr))
}
hist(tstat,col=col,freq=FALSE)
#segments(ci[1],0,ci[2],0,lwd=2)

return(list(pvalue=pvalue))
#return(list(pvalue=pvalue,tcalc=tcalc,n=n,x=x,test=test,ci=ci))
}

boot2pval(x1=y, x2= x, mudiff = 0)
boot2pval(x1=y, x2= x, mudiff = 2)
```

In this case, the p-value for $H_0: \mu_y - mu_x = 0$ is .0836, so the null hypothesis is accepted, which also occurred in task 3.
In this case, the p-value for $H_0: \mu_y - mu_x = 2$ is .5896, so the null hypothesis is accepted, which also occurred in task 3.
The bootstrap process created similar p-values as to the real p values.

# Task 6

## Bootstrap values for task 4

```{r}
set.seed(30);x=rnorm(15,mean=10,sd=4)   
set.seed(40);y=rnorm(20,mean=12,sd=4)

boot2pval(x1=y, x2= x, mudiff = 0)
boot2pval(x1=y, x2= x, mudiff = 2)
```

In this case, the p-value for $H_0: \mu_y - mu_x = 0$ is .048, so the null hypothesis is rejected, which also occurred in task 4.
In this case, the p-value for $H_0: \mu_y - mu_x = 2$ is .8336, so the null hypothesis is accepted, which also occurred in task 4.
The bootstrap process produces remarkably similar values to the p-values found in task 4.

# Task 7

## Output analysis

A: A one-sample t-test using x1 as a sample with a null hypothesis mean of 23.
B: The t-test program telling you that you are using a one sample t-test.
C: The t statistic (t), the number of degrees of freedom (df), and the p-value (p-value)
D: The alternative hypothesis to the null hypothesis that the mean is equal to 23.
E: The confidence interval for the mean, in this case a 95% confidence interval.
F: The lower and upper bounds on the confidence interval.
G: The calculated sample mean of the sample passed to the t-test function.

# Task 8

## My Package

Null hypothesis: $H_0: \mu_0 = 13$.

```{r}
set.seed(37);x1=rnorm(30,mean=15,sd=4)
tcalc = (mean(x1) - 13) / (sd(x1)/sqrt(length(x1)))
tcalc
MATH4753PREU0001::nathanpvalue(tcalc, n=length(x1))
```

In this case, the t-value, 1.8539, does not fall within the rejection region $t\gt 2.045$ or $t \lt -2.045$, so the null hypothesis is accepted.
